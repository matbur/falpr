{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "from tflearn import DNN\n",
    "from tflearn.datasets import mnist\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import fully_connected, input_data, dropout\n",
    "from tflearn.layers.estimator import regression\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOG_DIR = '/tmp/cypsio/'\n",
    "LOG_DIR = '../data/model/'\n",
    "# DATA_DIR = '../data/images_letters_normalized_together/'\n",
    "DATA_DIR = '../data/images_letters_normalized_cleaned_together/'\n",
    "\n",
    "TENSORBOARD_DIR = os.path.join(LOG_DIR, 'tensorboard')\n",
    "CHECKPOINT_PATH = os.path.join(LOG_DIR, 'checkpoint')\n",
    "MODEL_FILE = os.path.join(LOG_DIR, 'model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir, size=.8):\n",
    "    x = []\n",
    "    y = []\n",
    "    files = glob(os.path.join(data_dir, '*'))\n",
    "    random.shuffle(files)\n",
    "    for i in files:\n",
    "        img = cv2.imread(i, 0)\n",
    "        img_label = np.zeros(len(labels))\n",
    "        img_label[labels.index(os.path.basename(i).split('_')[0])] = 1\n",
    "        x.append(img)\n",
    "        y.append(img_label)\n",
    "    n = int(len(x) * size)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x[:n], y[:n], x[n:], y[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36586, 64, 64, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y = load_data(DATA_DIR)\n",
    "\n",
    "train_x = train_x.reshape([-1, 64, 64, 1])\n",
    "test_x = test_x.reshape([-1, 64, 64, 1])\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_input = input_data(shape=[None, 64, 64, 1])\n",
    "\n",
    "conv1 = conv_2d(net_input, nb_filter=4, filter_size=5, strides=[1, 1, 1, 1], activation='relu')\n",
    "max_pool1 = max_pool_2d(conv1, kernel_size=2)\n",
    "\n",
    "conv2 = conv_2d(max_pool1, nb_filter=8, filter_size=5, strides=[1, 2, 2, 1], activation='relu')\n",
    "max_pool2 = max_pool_2d(conv2, kernel_size=2)\n",
    "\n",
    "conv3 = conv_2d(max_pool2, nb_filter=12, filter_size=4, strides=[1, 1, 1, 1], activation='relu')\n",
    "max_pool3 = max_pool_2d(conv3, kernel_size=2)\n",
    "\n",
    "fc1 = fully_connected(max_pool3, n_units=200, activation='relu')\n",
    "drop1 = dropout(fc1, keep_prob=.5)\n",
    "\n",
    "fc2 = fully_connected(drop1, n_units=36, activation='softmax')\n",
    "net = regression(fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DNN(network=net,\n",
    "            tensorboard_dir=TENSORBOARD_DIR,\n",
    "            tensorboard_verbose=3,\n",
    "            best_checkpoint_path=CHECKPOINT_PATH,\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4575  | total loss: \u001b[1m\u001b[32m0.05232\u001b[0m\u001b[0m | time: 66.558s\n",
      "| Adam | epoch: 008 | loss: 0.05232 - acc: 0.9873 -- iter: 36544/36586\n",
      "Training Step: 4576  | total loss: \u001b[1m\u001b[32m0.05392\u001b[0m\u001b[0m | time: 72.395s\n",
      "| Adam | epoch: 008 | loss: 0.05392 - acc: 0.9854 | val_loss: 0.04607 - val_acc: 0.9892 -- iter: 36586/36586\n",
      "--\n",
      "INFO:tensorflow:/home/matbur/PycharmProjects/cypsio-pro/data/model/model_weights is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_inputs=train_x,\n",
    "          Y_targets=train_y,\n",
    "          validation_set=(test_x, test_y),\n",
    "          n_epoch=8,\n",
    "          show_metric=True,\n",
    "          run_id='CNN',\n",
    "         )\n",
    "model.save(MODEL_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
